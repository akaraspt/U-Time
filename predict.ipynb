{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06cb4e1-f56f-42e5-891a-0a9dff02ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c8de7-ae46-4986-9015-823bc1bd9a45",
   "metadata": {},
   "source": [
    "# Generate command to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d49f5-ffdc-4a3e-b367-180f0677a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '.'\n",
    "conf_f = os.path.join(data_dir, 'f_channel_1.csv')  # old: f_channel.csv\n",
    "conf_c = os.path.join(data_dir, 'c_channel_1.csv')  # old: c_channel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463b83b-4af2-411b-b520-6b68f33d2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_f_df = pd.read_csv(conf_f)\n",
    "conf_f_df = conf_f_df.iloc[:,1:]\n",
    "conf_f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e3269-3892-4943-b299-c9504dfb39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_c_df = pd.read_csv(conf_c)\n",
    "conf_c_df = conf_c_df.iloc[:,1:]\n",
    "conf_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266b7ed-95f1-4f3b-b8f3-1ff8b4ef0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_dir = './processed'\n",
    "map_db_dir = {\n",
    "    'mass_ss1': 'mass_ss1',\n",
    "    'mass_ss2': 'mass_ss2',\n",
    "    'mass_ss3': 'mass_ss3',\n",
    "    'mass_ss4': 'mass_ss4',\n",
    "    'mass_ss5': 'mass_ss5',\n",
    "    'SleepEDF': 'sedf_sc',\n",
    "    'isruc1': 'isruc_sg1', \n",
    "    'shhs1_normal': 'shhs1_nor',\n",
    "    'shhs1_osa': 'shhs1_osa',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225850d-5536-4738-9ec7-ad1d8842e00d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_cmd = 'cmd'\n",
    "commands = []\n",
    "count = 0\n",
    "for conf_df in [conf_f_df, conf_c_df]:\n",
    "    base_df = conf_df.groupby(by=['source_dataset','source_channel']).size().reset_index().rename(columns={0:'count'})\n",
    "    for _, b_row in base_df.iterrows():\n",
    "        # Base dataset\n",
    "        b_db = str(b_row['source_dataset']).lower()\n",
    "        b_ch = str(b_row['source_channel']).replace('EEG ','').replace(' ','-')\n",
    "        b_dir = os.path.join(local_data_dir, map_db_dir[b_row['source_dataset']], 'views/fixed_split')\n",
    "\n",
    "        # Base dataset\n",
    "        each_base_df = conf_df[(conf_df['source_dataset'] == b_row['source_dataset']) & (conf_df['source_channel'] == b_row['source_channel'])]\n",
    "        tran_df = each_base_df.groupby(by=['transfer_dataset']).size().reset_index().rename(columns={0:'count'})\n",
    "        \n",
    "        # Initialize command\n",
    "        src_proj = f\"{b_db.lower().replace(' ','_')}_{b_ch.lower()}_project\"\n",
    "        \n",
    "        for _, t_row in tran_df.iterrows():\n",
    "            t_chs = each_base_df[each_base_df['transfer_dataset'] == t_row['transfer_dataset']]['transfer_channel'].values\n",
    "            count += len(t_chs)\n",
    "            t_chs = '|'.join(t_chs)\n",
    "            t_chs = t_chs.replace('EEG ','').replace(' ', '-')\n",
    "            t_db = str(t_row['transfer_dataset']).lower()\n",
    "            t_dir = os.path.join(local_data_dir, map_db_dir[t_row['transfer_dataset']], 'views/fixed_split')\n",
    "            tgt_proj = f\"{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\"\n",
    "            \n",
    "            check1 = osp.isdir(f\"tf_{src_proj}__to__{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\")\n",
    "            check2 = osp.isfile(f\"{src_proj}/model/model_weights.h5\")\n",
    "            check3 = osp.isfile(f\"{tgt_proj}/model/model_weights.h5\")\n",
    "            if check1 and check2 and check3:\n",
    "                print(f\"cd tf_{src_proj}__to__{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\")\n",
    "                print(f\"ut predict --one_shot --save_true --out_dir ../predictions/{src_proj}__to__{tgt_proj}_type3 --weights_file_name '../{src_proj}/model/model_weights.h5' --overwrite\")\n",
    "                print(f\"ut predict --one_shot --save_true --out_dir ../predictions/{src_proj}__to__{tgt_proj}_type6 --weights_file_name '../{tgt_proj}/model/model_weights.h5' --overwrite\")\n",
    "                print(f\"ut predict --one_shot --save_true --out_dir ../predictions/{src_proj}__to__{tgt_proj}_type9 --overwrite\")\n",
    "                print(\"cd ..\")\n",
    "            # else:\n",
    "            #     print(f\" ** Skip tf_{src_proj}__to__{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28ecf7-1a70-4f10-b3b0-67350d08761a",
   "metadata": {},
   "source": [
    "# Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93185ae2-1627-4a4f-ba7a-102aa8321314",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for conf_df in [conf_f_df, conf_c_df]:\n",
    "    base_df = conf_df.groupby(by=['source_dataset','source_channel']).size().reset_index().rename(columns={0:'count'})\n",
    "    for _, b_row in base_df.iterrows():\n",
    "        # Base dataset\n",
    "        b_db = str(b_row['source_dataset']).lower()\n",
    "        b_ch = str(b_row['source_channel']).replace('EEG ','').replace(' ','-')\n",
    "        b_dir = os.path.join(local_data_dir, map_db_dir[b_row['source_dataset']], 'views/fixed_split')\n",
    "\n",
    "        # Base dataset\n",
    "        each_base_df = conf_df[(conf_df['source_dataset'] == b_row['source_dataset']) & (conf_df['source_channel'] == b_row['source_channel'])]\n",
    "        tran_df = each_base_df.groupby(by=['transfer_dataset']).size().reset_index().rename(columns={0:'count'})\n",
    "        \n",
    "        # Initialize command\n",
    "        src_proj = f\"{b_db.lower().replace(' ','_')}_{b_ch.lower()}_project\"\n",
    "        \n",
    "        for _, t_row in tran_df.iterrows():\n",
    "            t_chs = each_base_df[each_base_df['transfer_dataset'] == t_row['transfer_dataset']]['transfer_channel'].values\n",
    "            count += len(t_chs)\n",
    "            t_chs = '|'.join(t_chs)\n",
    "            t_chs = t_chs.replace('EEG ','').replace(' ', '-')\n",
    "            t_db = str(t_row['transfer_dataset']).lower()\n",
    "            t_dir = os.path.join(local_data_dir, map_db_dir[t_row['transfer_dataset']], 'views/fixed_split')\n",
    "            tgt_proj = f\"{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\"\n",
    "            \n",
    "            a_result = [\n",
    "                f\"{b_db.lower().replace(' ','_')}\", f\"eeg_{b_ch.lower().replace('-','_')}\",\n",
    "                f\"{t_db.lower().replace(' ','_')}\", f\"eeg_{t_chs.lower().replace('-','_')}\",\n",
    "            ]\n",
    "            for t in [3,6,9]:\n",
    "                scan_gt_path = osp.join(\n",
    "                    f\"predictions/{src_proj}__to__{tgt_proj}_type{t}\", 'test_data', 'dataset_1', '*_TRUE.npy'\n",
    "                )\n",
    "                gt_files = list(glob.glob(scan_gt_path))\n",
    "                if len(gt_files) > 0:\n",
    "                    y_trues = []\n",
    "                    y_preds = []\n",
    "                    for fp_gt in gt_files:\n",
    "                        fp_pred = fp_gt.replace('_TRUE.npy', '_PRED.npy')\n",
    "                        y_true = np.squeeze(np.load(fp_gt))\n",
    "                        y_pred = np.load(fp_pred)\n",
    "                        y_trues.extend(y_true)\n",
    "                        y_preds.extend(y_pred)\n",
    "                    y_trues, y_preds = np.array(y_trues), np.array(y_preds)\n",
    "                    a_result.extend([\n",
    "                        skm.accuracy_score(y_trues, y_preds),\n",
    "                        skm.f1_score(y_trues, y_preds, average='macro')\n",
    "                    ])\n",
    "                    # print(f\"{src_proj}__to__{tgt_proj}_type{t}\")\n",
    "                    # print(y_trues.shape, y_preds.shape)\n",
    "                    # print(f\"ACC: {skm.accuracy_score(y_trues, y_preds)}\")\n",
    "                    # print(f\"MF1: {skm.f1_score(y_trues, y_preds, average='macro')}\")\n",
    "                    # print(f\"PR: {skm.precision_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "                    # print(f\"RE: {skm.recall_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "                    # print(f\"F1: {skm.f1_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "            results.append(a_result)\n",
    "            \n",
    "tf_df = pd.DataFrame(results, columns=[\n",
    "    'source_dataset','source_channel','target_dataset','target_channel',\n",
    "    'acc_type3','mf1_type3','acc_type6','mf1_type6','acc_type9','mf1_type9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba21f77-0982-4dda-9e3a-df1400319ee2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d8c21-1860-47e1-aecb-d3b1c9adced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_df.to_csv('utime_conclusions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43e373-2264-45fb-8273-de099eaf5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run more with other weights for statistical tests\n",
    "\n",
    "results = []\n",
    "for temp in [2,3]:\n",
    "    for conf_df in [conf_f_df, conf_c_df]:\n",
    "        base_df = conf_df.groupby(by=['source_dataset','source_channel']).size().reset_index().rename(columns={0:'count'})\n",
    "        for _, b_row in base_df.iterrows():\n",
    "            # Base dataset\n",
    "            b_db = str(b_row['source_dataset']).lower()\n",
    "            b_ch = str(b_row['source_channel']).replace('EEG ','').replace(' ','-')\n",
    "            b_dir = os.path.join(local_data_dir, map_db_dir[b_row['source_dataset']], 'views/fixed_split')\n",
    "\n",
    "            # Base dataset\n",
    "            each_base_df = conf_df[(conf_df['source_dataset'] == b_row['source_dataset']) & (conf_df['source_channel'] == b_row['source_channel'])]\n",
    "            tran_df = each_base_df.groupby(by=['transfer_dataset']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "            # Initialize command\n",
    "            src_proj = f\"{b_db.lower().replace(' ','_')}_{b_ch.lower()}_project\"\n",
    "\n",
    "            for _, t_row in tran_df.iterrows():\n",
    "                t_chs = each_base_df[each_base_df['transfer_dataset'] == t_row['transfer_dataset']]['transfer_channel'].values\n",
    "                t_chs = '|'.join(t_chs)\n",
    "                t_chs = t_chs.replace('EEG ','').replace(' ', '-')\n",
    "                t_db = str(t_row['transfer_dataset']).lower()\n",
    "                t_dir = os.path.join(local_data_dir, map_db_dir[t_row['transfer_dataset']], 'views/fixed_split')\n",
    "                tgt_proj = f\"{t_db.lower().replace(' ','_')}_{t_chs.lower()}_project\"\n",
    "\n",
    "                a_result = [\n",
    "                    f\"{b_db.lower().replace(' ','_')}\", f\"eeg_{b_ch.lower().replace('-','_')}\",\n",
    "                    f\"{t_db.lower().replace(' ','_')}\", f\"eeg_{t_chs.lower().replace('-','_')}\",\n",
    "                ]\n",
    "\n",
    "                for t in [3,6,9]:\n",
    "                    scan_gt_path = osp.join(\n",
    "                        f\"predictions/{src_proj}__to__{tgt_proj}_type{t}_{temp}\", 'test_data', 'dataset_1', '*_TRUE.npy'\n",
    "                    )\n",
    "                    gt_files = list(glob.glob(scan_gt_path))\n",
    "                    if len(gt_files) > 0:\n",
    "                        y_trues = []\n",
    "                        y_preds = []\n",
    "                        for fp_gt in gt_files:\n",
    "                            fp_pred = fp_gt.replace('_TRUE.npy', '_PRED.npy')\n",
    "                            y_true = np.squeeze(np.load(fp_gt))\n",
    "                            y_pred = np.load(fp_pred)\n",
    "                            y_trues.extend(y_true)\n",
    "                            y_preds.extend(y_pred)\n",
    "                        y_trues, y_preds = np.array(y_trues), np.array(y_preds)\n",
    "                        a_result.extend([\n",
    "                            skm.accuracy_score(y_trues, y_preds),\n",
    "                            skm.f1_score(y_trues, y_preds, average='macro')\n",
    "                        ])\n",
    "                        # print(f\"{src_proj}__to__{tgt_proj}_type{t}\")\n",
    "                        # print(y_trues.shape, y_preds.shape)\n",
    "                        # print(f\"ACC: {skm.accuracy_score(y_trues, y_preds)}\")\n",
    "                        # print(f\"MF1: {skm.f1_score(y_trues, y_preds, average='macro')}\")\n",
    "                        # print(f\"PR: {skm.precision_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "                        # print(f\"RE: {skm.recall_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "                        # print(f\"F1: {skm.f1_score(y_trues, y_preds, average=None, labels=[0,1,2,3,4])}\")\n",
    "                if len(a_result) > 4:\n",
    "                    results.append(a_result)\n",
    "            \n",
    "tf_df = pd.DataFrame(results, columns=[\n",
    "    'source_dataset','source_channel','target_dataset','target_channel',\n",
    "    'acc_type3','mf1_type3','acc_type6','mf1_type6','acc_type9','mf1_type9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689742f-e4e1-47fa-8f0d-4184779188cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac9823-46a8-440d-aee9-372f3a993969",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.to_csv('utime_conclusions_more.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa35629-7aac-4ca4-ae1f-3c5e647ac2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
