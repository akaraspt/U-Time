{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86aba53-fb91-4cd5-ac35-71e7da50e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "from mne.filter import resample\n",
    "from scipy.signal import resample_poly\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79efc27b-0bac-47b3-963d-d2a781d06271",
   "metadata": {},
   "source": [
    "# Study U-Time h5 file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6a06d-cf4c-4272-8a5d-6fa5b12037d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5_file = '/home/akara/Workspace/U-Time/processed/mass_ss3/01-03-0001 PSG/01-03-0001 PSG.h5'\n",
    "# h5_file = '/home/akara/Workspace/U-Time/processed/mass_ss1/01-01-0001 PSG/01-01-0001 PSG.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17f42a-a945-4ac7-9d1a-272a094ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(h5_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212da389-c211-409f-8899-f897cd49d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e226152-3ae2-406d-932b-64f5c031497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f['channels'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126d7ae-c640-4556-bea2-793e17592eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.attrs.keys())\n",
    "for k in f.attrs.keys():\n",
    "    print(k, f.attrs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4c12e-fd24-4823-8f24-579079718d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "f['channels']['F4-CLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd94dc-cce4-4972-99ea-786eabd51d3c",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03517af5-1847-4f16-8c83-883c4b906e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "isruc_src_dir = '/home/akara/Workspace/sleep_data/isruc/subgroup_1'\n",
    "output_dir = '/home/akara/Workspace/U-Time/processed/isruc_sg1'\n",
    "isruc_fs = 200\n",
    "target_fs = 128\n",
    "select_expert = 1\n",
    "select_channels = [\n",
    "    'F3_A2', 'C3_A2',\n",
    "    'F4_A1', 'C4_A1',\n",
    "    'O1_A2', 'O2_A1',\n",
    "    'ROC_A1', 'LOC_A2']\n",
    "ann_dict = {\n",
    "    0: 'Sleep stage W',\n",
    "    1: 'Sleep stage 1',\n",
    "    2: 'Sleep stage 2',\n",
    "    3: 'Sleep stage 3',\n",
    "    4: 'Sleep stage R',\n",
    "    5: 'Sleep stage ?',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84fde6-16fa-4a69-98e0-d7618c453423",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat_files = glob.glob(os.path.join(isruc_src_dir, 'subject*.mat'))\n",
    "for subject_file in mat_files:\n",
    "    print(subject_file)\n",
    "    sid = os.path.basename(subject_file).split('.')[0]\n",
    "    sid = int(sid.replace('subject', ''))\n",
    "    ann_file = os.path.join(\n",
    "        os.path.dirname(subject_file), \n",
    "        'annotations', \n",
    "        f\"{sid}_{select_expert}.txt\")\n",
    "    mat = scipy.io.loadmat(subject_file)\n",
    "    signals = []\n",
    "    n_epochs = -1\n",
    "    for ch in select_channels:\n",
    "        if n_epochs == -1:\n",
    "            n_epochs = mat.get(ch).shape[0]\n",
    "        else:\n",
    "            assert n_epochs == mat.get(ch).shape[0]\n",
    "        signals.append(mat.get(ch).reshape(-1))\n",
    "        print(f'extracted {ch} channel {mat.get(ch).shape}')\n",
    "\n",
    "    # Signals\n",
    "    resampled_x = resample_poly(\n",
    "        np.swapaxes(np.array(signals),0,1).astype(np.float64),\n",
    "        target_fs,\n",
    "        isruc_fs,\n",
    "        axis=0)\n",
    "    \n",
    "    # Annotations\n",
    "    y_df = pd.read_csv(ann_file, header=None, names=['ann'])\n",
    "    y = y_df['ann'].values\n",
    "    y = y[:n_epochs]\n",
    "    # Replace the REM label from 5 to 4\n",
    "    y[y==5] = 4\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    # Saving signals to h5file\n",
    "    out_file = osp.basename(subject_file).split('.')[0]\n",
    "    out_subject_dir = osp.join(output_dir, f'{out_file} PSG')\n",
    "    out_signal_file = os.path.join(out_subject_dir, f'{out_file} PSG.h5')\n",
    "    out_ann_file = os.path.join(out_subject_dir, f'{out_file} Annotations.ids')\n",
    "    if not osp.isdir(out_subject_dir):\n",
    "        os.makedirs(out_subject_dir)\n",
    "    h5file = h5py.File(out_signal_file, 'w')\n",
    "    h5ch = h5file.create_group('channels')\n",
    "    for ch_i, ch in enumerate(select_channels):\n",
    "        h5ch.create_dataset(\n",
    "            ch.replace('_','-'), \n",
    "            data=resampled_x[:,ch_i], \n",
    "            dtype='float64')\n",
    "    print(h5file['channels'].keys())\n",
    "    for k in h5file['channels'].keys():\n",
    "        print(k, h5file['channels'][k])\n",
    "    # Sanity check\n",
    "    for ch in select_channels:\n",
    "        x_mat = resample_poly(\n",
    "            mat.get(ch).reshape(-1).astype(np.float64),\n",
    "            target_fs,\n",
    "            isruc_fs,\n",
    "            axis=0)\n",
    "        x_h5 = h5file['channels'][ch.replace('_','-')]\n",
    "        assert np.array_equal(x_mat, x_h5)\n",
    "    print('Pass sanity check')\n",
    "    \n",
    "    # Attribute for sample_rate\n",
    "    h5file.attrs.create('sample_rate', target_fs)\n",
    "    print(h5file.attrs.keys())\n",
    "    print(f\"Set sample_rate to {h5file.attrs['sample_rate']}\")\n",
    "\n",
    "    # Save h5 file\n",
    "    h5file.close()\n",
    "    print(f\"Saved extracted signals to {out_signal_file}\")\n",
    "\n",
    "    # Saving annotations into the standard format\n",
    "    print(y)\n",
    "    y_tran_idx = np.where(np.diff(y) != 0)[0] + 1\n",
    "    y_tran_idx = np.append(y_tran_idx, [len(y)])\n",
    "    print(f\"Total seconds: {resampled_x.shape[0] / target_fs}\")\n",
    "    with open(out_ann_file, 'w') as ann_f:\n",
    "        prev_end = 0\n",
    "        epoch_sec = 30\n",
    "        sum_dur = 0\n",
    "        for ti in range(len(y_tran_idx)):\n",
    "            if ti == 0:\n",
    "                start = 0\n",
    "                prev_yti = 0\n",
    "            else:\n",
    "                start = prev_start + prev_dur\n",
    "                prev_yti = y_tran_idx[ti-1]\n",
    "            dur = y_tran_idx[ti] - prev_yti\n",
    "            print(f\"{start*epoch_sec},{dur*epoch_sec},{ann_dict[y[y_tran_idx[ti]-1]]}\")\n",
    "            ann_f.write(f\"{start*epoch_sec},{dur*epoch_sec},{ann_dict[y[y_tran_idx[ti]-1]]}\\n\")\n",
    "            prev_start = start\n",
    "            prev_dur = dur\n",
    "            sum_dur += dur\n",
    "    print(f\"Saved annotations to {out_ann_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c2501-b62b-4325-8f1d-434260d7ccaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
